**2025-07-06**\
There are 3 kinds of multiplication in the ML I know thus far:
- inner product (standard matrix multiplication, the result is a matrix or a schalar)
- outer product (like the inner product, but with vectors, the result is a matrix)
- Kronecker product (it's like the outer product of 2 matrices, the result is a matrix bigger than the previous ones)

**2025-07-07**\
Today I was discussing the psychology of ML and studying, particularly my tendency to understnad the math equations and systems through aligning my inner feelings (emotions, proprioception, etc) with how the equation/system works. ChatGPT told me it's how top scientists work with their ideas. The possible names for this are:
- embodied learning
- algorithmic identification
- systemic empathy
- becoming-the-system
The problem is that when I impersonate some system, I begin work with myself, and it can be hurtful for the ego. I need to understand that I apply my tools to something external, and apply this embodied learning more sparingly.\
I completed (rewrote from the QWENs text) the program, and understood everything (not as solid as I understand FFNNs (I don't like this abbreviation)). The most difficult part for me is recreating the derivation of the softmax function (about why exactly dz[label]-=1), the explanation of it is rather long. But I'll return to it later, I'm sure it's not so hard to understand.


**2025-07-08**\
14:08:22. Today I read the code for the backpropagation of the fully connected and conv2d layers. Also I try to use the Sublime Text, because it compiles much faster than VSC. And I try to use the Sublime Merge to upload the code to the Github.

**2025-07-09**\
Idk why it doesn't want to insert the date and time in the format dd.mm.yyyy, but fuck it. I don't really care, let it be raw.\
So yesterday I spent a lot of time (whole day), trying to make VSC to work with both .py and .cpp code. It turned out that I just put all files into one folder with the same launch.json and tasks.json file, so those files couldn't operate the compilation and debbugging of all files (considering that C++ needs compilation, and Python doesn't, plus debuggers for them are different). So in the end I put them into 2 different folders, deleted the folders .vsc (to let VSC create blank ones) => and everything started to work. Then I asked ChatGPT and QWEN for some tweaks to those files to make everthing look better.

**2025-07-11**\
Explored the natural logarithms and their role in the calculation of the Cross-Entropy Loss. I'm rather familiar with it, but repeating to improve the understanding is a good idea.

**2025-07-12**\
Now I try to understand how the chain rule is implemented into the code:
```python
def grad_fully_connected(x, weights, probs, label):
    dlogits = probs.copy()
    dlogits[label] -= 1  # derivative of CE loss w.r.t logits
    dfc_weights = np.outer(dlogits, x)
    dfc_bias = dlogits
    dx = np.dot(weights.T, dlogits)
    return dfc_weights, dfc_bias, dx
```
Tough shit, I'd say. But not more difficult than when I started to study the simple feed-forward neural networks from the scrath.\
Ok, I spent an hour and started to fall asleep, unable to dig through the QWEN's explanations further, so I call it for today.\

**2025-07-14**\
Learning the derivative of the CE loss w.r.t. softmax output. I was studying it about a week ago, I guess, so I could recall it very fast.\
After that I jumped to the derivative of the softmax w.r.t. to logits: I studied it too, but it's more complicated, and I didn't study it really thoroughly, so now it's difficult task to understand it well. But I'm moving on.\
The time of studying: <1 hour. Not very impressive, but the task is difficult too.

**2025-07-18**\
Still reading about the explanation of CE loss w.r.t. softmax logits. I read again about the derivative of the L w.r.t. softmax output. And went again to the derivative of the softmax(?) w.r.t. to logits, or the Jacobian Matrix of the softmax(?). Anyway, I read a bit of chatgpt explanations and wathced a video https://www.youtube.com/watch?v=QexBVGVM690 on the channel of Christopher Lum, called The Jacobian Matrix (I skipped the physics part, because it's late night (1:27 am), and I'm not very interested in physics (at least, this kind), though it may be helpful to see the application of the Jacobian Matrix to something, even if it's not ML).

**2025-07-22**\
I guess today I understood the full gradient flow from CE loss->Softmax output->Softmax logits. Not as a full picture, but I as a big pile of logical steps. Will need some time to understand it naturally.

**2025-08-01**\
I learned about more intuitive understanding of why we need to transpose matrices and vectors during backpropagation and why it's different from the backpropagation of with scalars. The most intuitive understanding I've got is that operations with vectors and matrices is not commutative, leading to the need for transposing during backprop. But I can't visualize and intuitively understand the... flow of information that requres transposition. Maybe I've got too used to the usual scalar multuplication.
So now to understand it (and maybe something else along the way) I ask ChatGPT to write me the backpropagation process, using "for" loops and the usual matrix/vector operations. Undertanding both may give me some insights in how the "reversing of the flow" works.

**2025-08-05**\
Studying the function
```Python
def grad_max_pool(dpool_out, relu_out, size=2, stride=2):
```
and the bug that was in it before ChatGPT fixed it.

**2025-08-07**\
Completed the studying (and understanding) of the `def grad_max_pool()`. Then I switched to the Assembly language. I asked ChatGPT to write me a Hello World code, then I installed NASM and used it + gcc to launch the program. Also I installed the Oracle VirtualBox to launch .asm code. It's not about machine learning a lot, I just wanted to work a bit with the Assembly language. Though understanding of the asm language can give me an important context for my ML  learning process.
Btw I also found a bug in the fixed version of `def grad_max_pool()`. ChatGPT fixed the bug of the this function, made by the QWEN AI, but upon studying of the fixed version I noticed that the output shape of the function equals the input shape (d_relu=np.zeros_like(dpool_out)), and it shouldn't be like this for a pooling layer (forward and backward pass versions of the function) so I asked ChatGPT why it happened. And it said (I like to say she) that I'm correct, and it's a bug. Kinda proud of it. UPD: Hmm, I think I didn't fix the bug in the ChatGPT's code, I just rewrote it incorrectly, then "debugged" and told ChatGPT it was its mistake, and it agreed. What a shame.

**2025-08-08**\
Today I mostly studied the grad_relu() function (I kinda know it already, so took me about 5-10 minutes),  didn't write anything, but made my github page fancier. I created a main page README.md file and added an information that I deem improtant for me. But I think it mostly made the main page more friendly to the people who visit it. I'm not sure I need to tell that I like AGI and stuff. I think every ML engineer likes it. Or not?

**2025-08-18**\
Yesterday: figuring out the concept of linearity and nonlinearity, both in the mathematical and ML sense. In the math it's simple: if the graph of a function is a line. In ML it's more complicated: if 2 or more fields on the graph can be separated, so that on the one side of the line (not a curve or circle, etc) there are values of the function (y) equal to one number, and on the other side - to another number. This is what I can't wrap my head around with a big precision and nuances. Surely, I can draw the line, but what else it means in the bigger context - I have difficulties to understand.\
Also I want to implement another way of studying, to avoid burn out. The way is to study multiple subjects, not just ML. Usually I study something, until I can't force to stuff anymore into my head and feel disgust to the subject. But now I want to study like in the school: 1 hour I devote to ML, then (regardless if I'm tired or not) switch to studying hydroponics/motorcycles/business/astronomy/etc. This will prevent the situation when I feel like I'm a machine dedicated to machine learning and unaware of anything else.\
So yesterday I switched to reading of a book about plants biology (Raven, Biology of Plants, 8th edition), it's in English, so kinda difficult to read, but I feel refreshed, because there's something in my head except backpropagation, and today I can study ML again.\
For today, I studied the def grad_relu() part. Then I answered the quations of ChatGPT (I like the study mode of ChatGPT for this), and then tried to understand the Parametric ReLU (understood partially, then 1 hour timer rang).


**2025-08-19**\
Read and tried to understand the backprop of the convolutional layer, rewrite the bugged parts of the previous code (mostly typos), ChatGPT showed me them.












