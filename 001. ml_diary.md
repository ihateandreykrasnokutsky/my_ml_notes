**2025-07-02**

There are 3 kinds of multiplication in the ML I know thus far:
- inner product (standard matrix multiplication, the result is a matrix or a schalar)
- outer product (like the inner product, but with vectors, the result is a matrix)
- Kronecker product (it's like the outer product of 2 matrices, the result is a matrix bigger than the previous ones)

**2025-07-03**

Today I was discussing the psychology of ML and studying, particularly my tendency to understnad the math equations and systems through aligning my inner feelings (emotions, proprioception, etc) with how the equation/system works. ChatGPT told me it's how top scientists work with their ideas. The possible names for this are:
- embodied learning
- algorithmic identification
- systemic empathy
- becoming-the-system
The problem is that when I impersonate some system, I begin work with myself, and it can be hurtful for the ego. I need to understand that I apply my tools to something external, and apply this embodied learning more sparingly.

I completed (rewrote from the QWENs text) the program, and understood everything (not as solid as I understand FFNNs (I don't like this abbreviation)). The most difficult part for me is recreating the derivation of the softmax function (about why exactly dz[label]-=1), the explanation of it is rather long. But I'll return to it later, I'm sure it's not so hard to understand.












